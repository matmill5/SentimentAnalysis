{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import nltk \n",
    "from nltk.tokenize import word_tokenize\n",
    "import emoji\n",
    "from emoji.unicode_codes import UNICODE_EMOJI\n",
    "from textblob import TextBlob\n",
    "\n",
    "import sys\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "def sentimentTextBlob(file):\n",
    "\n",
    "    #loading the data into the dataframe\n",
    "    data=pd.read_csv(file, encoding='utf-8')\n",
    "    \n",
    "    data['text']=data.astype(str).apply(' '.join, axis=1)\n",
    "    data=pd.DataFrame(data['text'])\n",
    "    \n",
    "\n",
    "    #Removing the duplicate rows from text column and resetting index\n",
    "    data=data.drop_duplicates(['text'],keep='first')\n",
    "    data=data.reset_index(drop=True)\n",
    "    data['Original Text']=data['text']\n",
    "\n",
    "    #converting emoji into the text\n",
    "    import emoji\n",
    "    for i in range(len(data)):\n",
    "        data.loc[i,'text'] = emoji.demojize(data.loc[i,'text'])\n",
    "\n",
    "\n",
    "    #converting special character \"‚Äô\" to \"'\" for contraction\n",
    "    for i in range(len(data)):\n",
    "        data.loc[i,'text']=data.loc[i,'text'].replace(\"‚Äô\",\"'\")\n",
    "\n",
    "    sys.path.insert(0, 'C:\\\\Users\\\\gautam\\\\Desktop\\\\Tweets_Notebook')\n",
    "    from contractions_1 import CONTRACTION_MAP\n",
    "\n",
    "    def expand_contractions(text, contraction_mapping=CONTRACTION_MAP):\n",
    "\n",
    "        contractions_pattern = re.compile('({})'.format('|'.join(contraction_mapping.keys())), \n",
    "                                          flags=re.IGNORECASE|re.DOTALL)\n",
    "        def expand_match(contraction):\n",
    "            match = contraction.group(0)\n",
    "            first_char = match[0]\n",
    "            expanded_contraction = contraction_mapping.get(match)\\\n",
    "                                    if contraction_mapping.get(match)\\\n",
    "                                    else contraction_mapping.get(match.lower())                       \n",
    "            expanded_contraction = first_char+expanded_contraction[1:]\n",
    "            return expanded_contraction\n",
    "\n",
    "        expanded_text = contractions_pattern.sub(expand_match, text)\n",
    "        expanded_text = re.sub(\"'\", \"\", expanded_text)\n",
    "        return expanded_text\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        data.loc[i,'text'] = expand_contractions(str(data.loc[i,'text']))\n",
    "\n",
    "\n",
    "    #data cleaning steps\n",
    "    for i in range(len(data)):\n",
    "        # Remove the word starting with @\n",
    "        data.loc[i,'text'] = re.sub(r'@[A-Za-z0-9]+', ' ', str(data.loc[i,'text']))\n",
    "\n",
    "        #Remove URL links\n",
    "        data.loc[i,'text']  = re.sub('https?://[A-Za-z0-9./]+',' ',data.loc[i,'text'] ) \n",
    "        data.loc[i,'text']  = re.sub('http?://[A-Za-z0-9./]+',' ',data.loc[i,'text'] )\n",
    "\n",
    "\n",
    "        # Converting to Lowercase\n",
    "        data.loc[i,'text']  = data.loc[i,'text'] .lower()\n",
    "\n",
    "        #Remove the new line characters\n",
    "        data.loc[i,'text'] = re.sub(r\"\\t|\\n|\\r\", \" \", data.loc[i,'text'] , flags=re.I)\n",
    "\n",
    "        #Remove punctuation\n",
    "        data.loc[i,'text'] = re.sub(r\"[,‚Äò@\\#-:'?\\.$%_!()&;+‚Äù/‚Ä¶*‚Ä¢|‚Äú]\", \" \", data.loc[i,'text'] , flags=re.I)\n",
    "\n",
    "        #Remove duble quotes\n",
    "        data.loc[i,'text'] = re.sub(r'\"', \" \", data.loc[i,'text'] , flags=re.I)\n",
    "\n",
    "        #Remove digits\n",
    "        data.loc[i,'text'] = re.sub(r\"\\d\", \"\", data.loc[i,'text'] )\n",
    "\n",
    "        # remove all single characters\n",
    "        data.loc[i,'text'] = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', data.loc[i,'text'] )\n",
    "\n",
    "        # Substituting multiple spaces with single space\n",
    "        data.loc[i,'text']  = re.sub(r'\\s+', ' ', data.loc[i,'text'] , flags=re.I)\n",
    "\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        # removing rt from the data\n",
    "        data.loc[i, 'text']=' '.join([x for x in data.loc[i,'text'].split() if x !='rt' and x !='nan'])  \n",
    "\n",
    "         # remove all single characters\n",
    "        data.loc[i,'text'] = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', data.loc[i,'text'] )\n",
    "\n",
    "        # Substituting multiple spaces with single space\n",
    "        data.loc[i,'text']  = re.sub(r'\\s+', ' ', data.loc[i,'text'] , flags=re.I)\n",
    "\n",
    "    # remove remaining tokens that are not alphabetic\n",
    "    for i in range(len(data)):\n",
    "        data.loc[i, 'text']=' '.join([x for x in data.loc[i,'text'].split() if x.isalpha()])\n",
    "    #     data.loc[i,'text'] = [word for word in data.loc[i,'text'] if word.isalpha()]\n",
    "\n",
    "\n",
    "\n",
    "    stop_words = stopwords.words('english')\n",
    "    stop_words.remove('no')\n",
    "    stop_words.remove('not')\n",
    "    for i in range(len(data)):\n",
    "        data.loc[i,'text'] = ' '.join([word for word in data.loc[i,'text'].split() if not word in stop_words])\n",
    "\n",
    "\n",
    "    # Lemmetization of words (it will change the word in the base form)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    for i in range(len(data)):\n",
    "        data.loc[i,'text'] = ' '.join([lemmatizer.lemmatize(word,pos='a') for word in data.loc[i,'text'].split()])\n",
    "        data.loc[i,'text'] = ' '.join([lemmatizer.lemmatize(word,pos='v') for word in data.loc[i,'text'].split()])\n",
    "        data.loc[i,'text'] = ' '.join([lemmatizer.lemmatize(word,pos='n') for word in data.loc[i,'text'].split()])\n",
    "\n",
    "    #Checking the words are english word or not, if not then remove it.\n",
    "#     from nltk.corpus import words\n",
    "#     for i in range(len(data)):\n",
    "#         data.loc[i,'text'] = ' '.join([word for word in data.loc[i,'text'].split() if word in words.words()])\n",
    "\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        # remove all single characters\n",
    "        data.loc[i,'text'] = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', data.loc[i,'text'] )\n",
    "\n",
    "        # Substituting multiple spaces with single space\n",
    "        data.loc[i,'text']  = re.sub(r'\\s+', ' ', data.loc[i,'text'] , flags=re.I)\n",
    "\n",
    "\n",
    "    for x in range(len(data)):\n",
    "        #print(data_1.loc[x,'text'])\n",
    "        data_sentiment=TextBlob(data.loc[x,'text'])\n",
    "        #data.translate(from_lang='auto',to='en')\n",
    "        data.loc[x,'Sentiment']=data_sentiment.sentiment.polarity\n",
    "\n",
    "    data['Sentiment_rolled']= data['Sentiment'].apply(lambda x:  1 if x > 0.1 else (0 if x == 0  else -1))\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_1='D:\\\\Manisha\\\\Undergrad_Semester\\\\Semesters\\\\Fall2019\\\\capstone\\\\System.tweets_esports_olympics_Text.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "output=sentimentTextBlob(file_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Original Text</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Sentiment_rolled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>best player go head head whole world see start...</td>\n",
       "      <td>RT @IntelGaming: The best @RocketLeague player...</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>trophy lequip special olympics catalunya sha p...</td>\n",
       "      <td>RT @btvesports: üèÜ L'equip Special Olympics Cat...</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>best player go head head whole world see start...</td>\n",
       "      <td>RT @IntelGaming: The best @StreetFighter playe...</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>https://t.co/wBIbIBMLkc</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>team international olympic committee intel wor...</td>\n",
       "      <td>The team-up of The International Olympic Commi...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  best player go head head whole world see start...   \n",
       "1  trophy lequip special olympics catalunya sha p...   \n",
       "2  best player go head head whole world see start...   \n",
       "3                                                      \n",
       "4  team international olympic committee intel wor...   \n",
       "\n",
       "                                       Original Text  Sentiment  \\\n",
       "0  RT @IntelGaming: The best @RocketLeague player...   0.400000   \n",
       "1  RT @btvesports: üèÜ L'equip Special Olympics Cat...   0.357143   \n",
       "2  RT @IntelGaming: The best @StreetFighter playe...   0.400000   \n",
       "3                            https://t.co/wBIbIBMLkc   0.000000   \n",
       "4  The team-up of The International Olympic Commi...   0.000000   \n",
       "\n",
       "   Sentiment_rolled  \n",
       "0                 1  \n",
       "1                 1  \n",
       "2                 1  \n",
       "3                 0  \n",
       "4                 0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_2='D:\\\\Manisha\\\\Undergrad_Semester\\\\Semesters\\\\Fall2019\\\\capstone\\\\data_sources\\\\Destination_Kent_State_Student_Evaluation_2017.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "output2=sentimentTextBlob(file_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Original Text</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Sentiment_rolled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>open end response open end response open end r...</td>\n",
       "      <td>Open-Ended Response Open-Ended Response Open-E...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>graduate diploma give money</td>\n",
       "      <td>nan nan nan nan nan To graduate with a diploma...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>nan nan nan nan nan nan nan</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>campus tour lunch best</td>\n",
       "      <td>nan nan nan Campus tours Lunch To do my best. nan</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spend night dorm helpful involve campus activi...</td>\n",
       "      <td>nan nan nan nan Spending a night in the dorms ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>no would tour downtown kent walk around downto...</td>\n",
       "      <td>nan nan nan No. It would be touring Downtown K...</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>college different high school talk flash guide...</td>\n",
       "      <td>nan nan nan how college is different from high...</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>talk flashguides life like campus personal exp...</td>\n",
       "      <td>nan nan nan nan Talking to the flashguides abo...</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>make sure set good amount time aside exam allo...</td>\n",
       "      <td>Make sure that they set a good amount of time ...</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>buy book food live goal expectation</td>\n",
       "      <td>nan nan nan Buying books and when to do that. ...</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>timeline bill process downtown tour great way ...</td>\n",
       "      <td>nan nan nan Timeline of billing process. Downt...</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>pas class not fail</td>\n",
       "      <td>nan nan nan nan nan To pass my classes and not...</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>self sufficient independent responsible</td>\n",
       "      <td>nan nan nan nan nan Be self sufficient (indepe...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>level difficulty test maybe easy question firs...</td>\n",
       "      <td>Level out the difficulty of the test to maybe ...</td>\n",
       "      <td>0.397549</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>go town able walk around make new friend way g...</td>\n",
       "      <td>nan nan nan nan Going into town and being able...</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  \\\n",
       "0   open end response open end response open end r...   \n",
       "1                         graduate diploma give money   \n",
       "2                                                       \n",
       "3                              campus tour lunch best   \n",
       "4   spend night dorm helpful involve campus activi...   \n",
       "5   no would tour downtown kent walk around downto...   \n",
       "6   college different high school talk flash guide...   \n",
       "7   talk flashguides life like campus personal exp...   \n",
       "8   make sure set good amount time aside exam allo...   \n",
       "9                 buy book food live goal expectation   \n",
       "10  timeline bill process downtown tour great way ...   \n",
       "11                                 pas class not fail   \n",
       "12            self sufficient independent responsible   \n",
       "13  level difficulty test maybe easy question firs...   \n",
       "14  go town able walk around make new friend way g...   \n",
       "\n",
       "                                        Original Text  Sentiment  \\\n",
       "0   Open-Ended Response Open-Ended Response Open-E...   0.000000   \n",
       "1   nan nan nan nan nan To graduate with a diploma...   0.000000   \n",
       "2                         nan nan nan nan nan nan nan   0.000000   \n",
       "3   nan nan nan Campus tours Lunch To do my best. nan   1.000000   \n",
       "4   nan nan nan nan Spending a night in the dorms ...   0.000000   \n",
       "5   nan nan nan No. It would be touring Downtown K...   0.450000   \n",
       "6   nan nan nan how college is different from high...   0.080000   \n",
       "7   nan nan nan nan Talking to the flashguides abo...   0.266667   \n",
       "8   Make sure that they set a good amount of time ...   0.566667   \n",
       "9   nan nan nan Buying books and when to do that. ...   0.136364   \n",
       "10  nan nan nan Timeline of billing process. Downt...   0.800000   \n",
       "11  nan nan nan nan nan To pass my classes and not...   0.250000   \n",
       "12  nan nan nan nan nan Be self sufficient (indepe...   0.100000   \n",
       "13  Level out the difficulty of the test to maybe ...   0.397549   \n",
       "14  nan nan nan nan Going into town and being able...   0.318182   \n",
       "\n",
       "    Sentiment_rolled  \n",
       "0                  0  \n",
       "1                  0  \n",
       "2                  0  \n",
       "3                  1  \n",
       "4                  0  \n",
       "5                  1  \n",
       "6                 -1  \n",
       "7                  1  \n",
       "8                  1  \n",
       "9                  1  \n",
       "10                 1  \n",
       "11                 1  \n",
       "12                -1  \n",
       "13                 1  \n",
       "14                 1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output2.head(15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
