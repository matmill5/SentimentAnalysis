{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import nltk \n",
    "from nltk.tokenize import word_tokenize\n",
    "import emoji\n",
    "from emoji.unicode_codes import UNICODE_EMOJI\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "\n",
    "import sys\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "def sentimentVader(file):\n",
    "\n",
    "    #loading the data into the dataframe\n",
    "    data=pd.read_csv(file, encoding='utf-8')\n",
    "    \n",
    "    data['text']=data.astype(str).apply(' '.join, axis=1)\n",
    "    data=pd.DataFrame(data['text'])\n",
    "    \n",
    "\n",
    "    #Removing the duplicate rows from text column and resetting index\n",
    "    data=data.drop_duplicates(['text'],keep='first')\n",
    "    data=data.reset_index(drop=True)\n",
    "    data['Original Text']=data['text']\n",
    "\n",
    "    #converting emoji into the text\n",
    "    import emoji\n",
    "    for i in range(len(data)):\n",
    "        data.loc[i,'text'] = emoji.demojize(data.loc[i,'text'])\n",
    "\n",
    "\n",
    "    #converting special character \"‚Äô\" to \"'\" for contraction\n",
    "    for i in range(len(data)):\n",
    "        data.loc[i,'text']=data.loc[i,'text'].replace(\"‚Äô\",\"'\")\n",
    "\n",
    "    sys.path.insert(0, 'C:\\\\Users\\\\gautam\\\\Desktop\\\\Tweets_Notebook')\n",
    "    from contractions_1 import CONTRACTION_MAP\n",
    "\n",
    "    def expand_contractions(text, contraction_mapping=CONTRACTION_MAP):\n",
    "\n",
    "        contractions_pattern = re.compile('({})'.format('|'.join(contraction_mapping.keys())), \n",
    "                                          flags=re.IGNORECASE|re.DOTALL)\n",
    "        def expand_match(contraction):\n",
    "            match = contraction.group(0)\n",
    "            first_char = match[0]\n",
    "            expanded_contraction = contraction_mapping.get(match)\\\n",
    "                                    if contraction_mapping.get(match)\\\n",
    "                                    else contraction_mapping.get(match.lower())                       \n",
    "            expanded_contraction = first_char+expanded_contraction[1:]\n",
    "            return expanded_contraction\n",
    "\n",
    "        expanded_text = contractions_pattern.sub(expand_match, text)\n",
    "        expanded_text = re.sub(\"'\", \"\", expanded_text)\n",
    "        return expanded_text\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        data.loc[i,'text'] = expand_contractions(str(data.loc[i,'text']))\n",
    "\n",
    "\n",
    "    #data cleaning steps\n",
    "    for i in range(len(data)):\n",
    "        # Remove the word starting with @\n",
    "        data.loc[i,'text'] = re.sub(r'@[A-Za-z0-9]+', ' ', str(data.loc[i,'text']))\n",
    "\n",
    "        #Remove URL links\n",
    "        data.loc[i,'text']  = re.sub('https?://[A-Za-z0-9./]+',' ',data.loc[i,'text'] ) \n",
    "        data.loc[i,'text']  = re.sub('http?://[A-Za-z0-9./]+',' ',data.loc[i,'text'] )\n",
    "\n",
    "\n",
    "        # Converting to Lowercase\n",
    "        data.loc[i,'text']  = data.loc[i,'text'] .lower()\n",
    "\n",
    "        #Remove the new line characters\n",
    "        data.loc[i,'text'] = re.sub(r\"\\t|\\n|\\r\", \" \", data.loc[i,'text'] , flags=re.I)\n",
    "\n",
    "        #Remove punctuation\n",
    "        data.loc[i,'text'] = re.sub(r\"[,‚Äò@\\#-:'?\\.$%_!()&;+‚Äù/‚Ä¶*‚Ä¢|‚Äú]\", \" \", data.loc[i,'text'] , flags=re.I)\n",
    "\n",
    "        #Remove duble quotes\n",
    "        data.loc[i,'text'] = re.sub(r'\"', \" \", data.loc[i,'text'] , flags=re.I)\n",
    "\n",
    "        #Remove digits\n",
    "        data.loc[i,'text'] = re.sub(r\"\\d\", \"\", data.loc[i,'text'] )\n",
    "\n",
    "        # remove all single characters\n",
    "        data.loc[i,'text'] = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', data.loc[i,'text'] )\n",
    "\n",
    "        # Substituting multiple spaces with single space\n",
    "        data.loc[i,'text']  = re.sub(r'\\s+', ' ', data.loc[i,'text'] , flags=re.I)\n",
    "\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        # removing rt from the data\n",
    "        data.loc[i, 'text']=' '.join([x for x in data.loc[i,'text'].split() if x !='rt' and x !='nan'])  \n",
    "\n",
    "         # remove all single characters\n",
    "        data.loc[i,'text'] = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', data.loc[i,'text'] )\n",
    "\n",
    "        # Substituting multiple spaces with single space\n",
    "        data.loc[i,'text']  = re.sub(r'\\s+', ' ', data.loc[i,'text'] , flags=re.I)\n",
    "\n",
    "    # remove remaining tokens that are not alphabetic\n",
    "    for i in range(len(data)):\n",
    "        data.loc[i, 'text']=' '.join([x for x in data.loc[i,'text'].split() if x.isalpha()])\n",
    "    #     data.loc[i,'text'] = [word for word in data.loc[i,'text'] if word.isalpha()]\n",
    "\n",
    "\n",
    "\n",
    "    stop_words = stopwords.words('english')\n",
    "    stop_words.remove('no')\n",
    "    stop_words.remove('not')\n",
    "    for i in range(len(data)):\n",
    "        data.loc[i,'text'] = ' '.join([word for word in data.loc[i,'text'].split() if not word in stop_words])\n",
    "\n",
    "\n",
    "    # Lemmetization of words (it will change the word in the base form)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    for i in range(len(data)):\n",
    "        data.loc[i,'text'] = ' '.join([lemmatizer.lemmatize(word,pos='a') for word in data.loc[i,'text'].split()])\n",
    "        data.loc[i,'text'] = ' '.join([lemmatizer.lemmatize(word,pos='v') for word in data.loc[i,'text'].split()])\n",
    "        data.loc[i,'text'] = ' '.join([lemmatizer.lemmatize(word,pos='n') for word in data.loc[i,'text'].split()])\n",
    "\n",
    "    #Checking the words are english word or not, if not then remove it.\n",
    "#     from nltk.corpus import words\n",
    "#     for i in range(len(data)):\n",
    "#         data.loc[i,'text'] = ' '.join([word for word in data.loc[i,'text'].split() if word in words.words()])\n",
    "\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        # remove all single characters\n",
    "        data.loc[i,'text'] = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', data.loc[i,'text'] )\n",
    "\n",
    "        # Substituting multiple spaces with single space\n",
    "        data.loc[i,'text']  = re.sub(r'\\s+', ' ', data.loc[i,'text'] , flags=re.I)\n",
    "\n",
    "\n",
    "    for x in range(len(data)):\n",
    "        #print(data_1.loc[x,'text'])\n",
    "        data_sentiment = SentimentIntensityAnalyzer()\n",
    "        data.loc[x,'Sentiment']=data_sentiment.polarity_scores(data.loc[x,'text'])['compound']\n",
    "        \n",
    "    data['Sentiment_rolled']= data['Sentiment'].apply(lambda x:  1 if x > 0.05 else (0 if (x <=0.05 and x>=-0.05)  else -1))\n",
    "    data['Polarity'] = data['Sentiment_rolled'].apply(lambda x:  'Positive' if x ==1  else ('Neutral' if x == 0  else 'Negative'))\n",
    "    \n",
    "    data.to_csv('predicted_sentiment.csv', index=False)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_1='D:\\\\Manisha\\\\Undergrad_Semester\\\\Semesters\\\\Fall2019\\\\capstone\\\\System.tweets_esports_olympics_Text.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output=sentimentVader(file_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Original Text</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Sentiment_rolled</th>\n",
       "      <th>Polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>best player go head head whole world see start...</td>\n",
       "      <td>RT @IntelGaming: The best @RocketLeague player...</td>\n",
       "      <td>0.6369</td>\n",
       "      <td>1</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>trophy lequip special olympics catalunya sha p...</td>\n",
       "      <td>RT @btvesports: üèÜ L'equip Special Olympics Cat...</td>\n",
       "      <td>0.4019</td>\n",
       "      <td>1</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>best player go head head whole world see start...</td>\n",
       "      <td>RT @IntelGaming: The best @StreetFighter playe...</td>\n",
       "      <td>0.6369</td>\n",
       "      <td>1</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>https://t.co/wBIbIBMLkc</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>team international olympic committee intel wor...</td>\n",
       "      <td>The team-up of The International Olympic Commi...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>esports no place olympics get outside get fres...</td>\n",
       "      <td>@BrendanHickey1 ESports has no place in The Ol...</td>\n",
       "      <td>0.0258</td>\n",
       "      <td>0</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>research ancient greek certainly not plan anno...</td>\n",
       "      <td>RT @t4_research: The ancient Greeks certainly ...</td>\n",
       "      <td>0.3400</td>\n",
       "      <td>1</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>excite bring intel world open esports tourname...</td>\n",
       "      <td>RT @IntelGaming: We are excited to bring the I...</td>\n",
       "      <td>0.7906</td>\n",
       "      <td>1</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>stoke esports</td>\n",
       "      <td>Stoked for #esports in the @Olympics !! https:...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>esports still talk olympics still look great b...</td>\n",
       "      <td>eSports is still in talks to be in the Olympic...</td>\n",
       "      <td>0.7430</td>\n",
       "      <td>1</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>esports track amp field amp fortnite esports s...</td>\n",
       "      <td>RT @finder_esports: Track &amp;amp; Field‚Ä¶&amp;amp; Fo...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ninja say video game olympic sport matter time...</td>\n",
       "      <td>Ninja Says Video Games Will Be an Olympic Spor...</td>\n",
       "      <td>0.0258</td>\n",
       "      <td>0</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ancient greek certainly not plan announce inte...</td>\n",
       "      <td>The ancient Greeks certainly didn‚Äôt plan for t...</td>\n",
       "      <td>0.3400</td>\n",
       "      <td>1</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>game effort send along isitasport decision mat...</td>\n",
       "      <td>A game effort, but I've sent along the #IsItAS...</td>\n",
       "      <td>0.4019</td>\n",
       "      <td>1</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>love esports beeing part olympics dont know</td>\n",
       "      <td>i love esports, but beeing part of the olympic...</td>\n",
       "      <td>0.6369</td>\n",
       "      <td>1</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>track amp field amp fortnite esports scene big...</td>\n",
       "      <td>Track &amp;amp; Field‚Ä¶&amp;amp; Fortnite???\\n\\nThe esp...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>soccer ball enhorabona tot el equip pel gran c...</td>\n",
       "      <td>RT @SOCatalunya: ‚öΩÔ∏è Enhorabona a tots els equi...</td>\n",
       "      <td>0.4019</td>\n",
       "      <td>1</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>olympics wing el primer torneo por parte de do...</td>\n",
       "      <td>Olympicss Wingss | El Primer Torneo por parte ...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>every stream fill esports commentary rocketlea...</td>\n",
       "      <td>Every stream filled with:\\n \\n - #esports comm...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>liglalerts esports star ninja matter time vide...</td>\n",
       "      <td>RT @LIGamingLeague: #LIGLAlerts ESports Star N...</td>\n",
       "      <td>0.0258</td>\n",
       "      <td>0</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  \\\n",
       "0   best player go head head whole world see start...   \n",
       "1   trophy lequip special olympics catalunya sha p...   \n",
       "2   best player go head head whole world see start...   \n",
       "3                                                       \n",
       "4   team international olympic committee intel wor...   \n",
       "5   esports no place olympics get outside get fres...   \n",
       "6   research ancient greek certainly not plan anno...   \n",
       "7   excite bring intel world open esports tourname...   \n",
       "8                                       stoke esports   \n",
       "9   esports still talk olympics still look great b...   \n",
       "10  esports track amp field amp fortnite esports s...   \n",
       "11  ninja say video game olympic sport matter time...   \n",
       "12  ancient greek certainly not plan announce inte...   \n",
       "13  game effort send along isitasport decision mat...   \n",
       "14        love esports beeing part olympics dont know   \n",
       "15  track amp field amp fortnite esports scene big...   \n",
       "16  soccer ball enhorabona tot el equip pel gran c...   \n",
       "17  olympics wing el primer torneo por parte de do...   \n",
       "18  every stream fill esports commentary rocketlea...   \n",
       "19  liglalerts esports star ninja matter time vide...   \n",
       "\n",
       "                                        Original Text  Sentiment  \\\n",
       "0   RT @IntelGaming: The best @RocketLeague player...     0.6369   \n",
       "1   RT @btvesports: üèÜ L'equip Special Olympics Cat...     0.4019   \n",
       "2   RT @IntelGaming: The best @StreetFighter playe...     0.6369   \n",
       "3                             https://t.co/wBIbIBMLkc     0.0000   \n",
       "4   The team-up of The International Olympic Commi...     0.0000   \n",
       "5   @BrendanHickey1 ESports has no place in The Ol...     0.0258   \n",
       "6   RT @t4_research: The ancient Greeks certainly ...     0.3400   \n",
       "7   RT @IntelGaming: We are excited to bring the I...     0.7906   \n",
       "8   Stoked for #esports in the @Olympics !! https:...     0.0000   \n",
       "9   eSports is still in talks to be in the Olympic...     0.7430   \n",
       "10  RT @finder_esports: Track &amp; Field‚Ä¶&amp; Fo...     0.0000   \n",
       "11  Ninja Says Video Games Will Be an Olympic Spor...     0.0258   \n",
       "12  The ancient Greeks certainly didn‚Äôt plan for t...     0.3400   \n",
       "13  A game effort, but I've sent along the #IsItAS...     0.4019   \n",
       "14  i love esports, but beeing part of the olympic...     0.6369   \n",
       "15  Track &amp; Field‚Ä¶&amp; Fortnite???\\n\\nThe esp...     0.0000   \n",
       "16  RT @SOCatalunya: ‚öΩÔ∏è Enhorabona a tots els equi...     0.4019   \n",
       "17  Olympicss Wingss | El Primer Torneo por parte ...     0.0000   \n",
       "18  Every stream filled with:\\n \\n - #esports comm...     0.0000   \n",
       "19  RT @LIGamingLeague: #LIGLAlerts ESports Star N...     0.0258   \n",
       "\n",
       "    Sentiment_rolled  Polarity  \n",
       "0                  1  Positive  \n",
       "1                  1  Positive  \n",
       "2                  1  Positive  \n",
       "3                  0   Neutral  \n",
       "4                  0   Neutral  \n",
       "5                  0   Neutral  \n",
       "6                  1  Positive  \n",
       "7                  1  Positive  \n",
       "8                  0   Neutral  \n",
       "9                  1  Positive  \n",
       "10                 0   Neutral  \n",
       "11                 0   Neutral  \n",
       "12                 1  Positive  \n",
       "13                 1  Positive  \n",
       "14                 1  Positive  \n",
       "15                 0   Neutral  \n",
       "16                 1  Positive  \n",
       "17                 0   Neutral  \n",
       "18                 0   Neutral  \n",
       "19                 0   Neutral  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_2='D:\\\\Manisha\\\\Undergrad_Semester\\\\Semesters\\\\Fall2019\\\\capstone\\\\data_sources\\\\Destination_Kent_State_Student_Evaluation_2017.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "output2=sentimentVader(file_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Original Text</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Sentiment_rolled</th>\n",
       "      <th>Polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>open end response open end response open end r...</td>\n",
       "      <td>Open-Ended Response Open-Ended Response Open-E...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>graduate diploma give money</td>\n",
       "      <td>nan nan nan nan nan To graduate with a diploma...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>nan nan nan nan nan nan nan</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>campus tour lunch best</td>\n",
       "      <td>nan nan nan Campus tours Lunch To do my best. nan</td>\n",
       "      <td>0.6369</td>\n",
       "      <td>1</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spend night dorm helpful involve campus activi...</td>\n",
       "      <td>nan nan nan nan Spending a night in the dorms ...</td>\n",
       "      <td>0.5267</td>\n",
       "      <td>1</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>no would tour downtown kent walk around downto...</td>\n",
       "      <td>nan nan nan No. It would be touring Downtown K...</td>\n",
       "      <td>0.7783</td>\n",
       "      <td>1</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>college different high school talk flash guide...</td>\n",
       "      <td>nan nan nan how college is different from high...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>talk flashguides life like campus personal exp...</td>\n",
       "      <td>nan nan nan nan Talking to the flashguides abo...</td>\n",
       "      <td>0.8271</td>\n",
       "      <td>1</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>make sure set good amount time aside exam allo...</td>\n",
       "      <td>Make sure that they set a good amount of time ...</td>\n",
       "      <td>0.8311</td>\n",
       "      <td>1</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>buy book food live goal expectation</td>\n",
       "      <td>nan nan nan Buying books and when to do that. ...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>timeline bill process downtown tour great way ...</td>\n",
       "      <td>nan nan nan Timeline of billing process. Downt...</td>\n",
       "      <td>0.8074</td>\n",
       "      <td>1</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>pas class not fail</td>\n",
       "      <td>nan nan nan nan nan To pass my classes and not...</td>\n",
       "      <td>0.4310</td>\n",
       "      <td>1</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>self sufficient independent responsible</td>\n",
       "      <td>nan nan nan nan nan Be self sufficient (indepe...</td>\n",
       "      <td>0.3182</td>\n",
       "      <td>1</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>level difficulty test maybe easy question firs...</td>\n",
       "      <td>Level out the difficulty of the test to maybe ...</td>\n",
       "      <td>0.9982</td>\n",
       "      <td>1</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>go town able walk around make new friend way g...</td>\n",
       "      <td>nan nan nan nan Going into town and being able...</td>\n",
       "      <td>0.7506</td>\n",
       "      <td>1</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  \\\n",
       "0   open end response open end response open end r...   \n",
       "1                         graduate diploma give money   \n",
       "2                                                       \n",
       "3                              campus tour lunch best   \n",
       "4   spend night dorm helpful involve campus activi...   \n",
       "5   no would tour downtown kent walk around downto...   \n",
       "6   college different high school talk flash guide...   \n",
       "7   talk flashguides life like campus personal exp...   \n",
       "8   make sure set good amount time aside exam allo...   \n",
       "9                 buy book food live goal expectation   \n",
       "10  timeline bill process downtown tour great way ...   \n",
       "11                                 pas class not fail   \n",
       "12            self sufficient independent responsible   \n",
       "13  level difficulty test maybe easy question firs...   \n",
       "14  go town able walk around make new friend way g...   \n",
       "\n",
       "                                        Original Text  Sentiment  \\\n",
       "0   Open-Ended Response Open-Ended Response Open-E...     0.0000   \n",
       "1   nan nan nan nan nan To graduate with a diploma...     0.0000   \n",
       "2                         nan nan nan nan nan nan nan     0.0000   \n",
       "3   nan nan nan Campus tours Lunch To do my best. nan     0.6369   \n",
       "4   nan nan nan nan Spending a night in the dorms ...     0.5267   \n",
       "5   nan nan nan No. It would be touring Downtown K...     0.7783   \n",
       "6   nan nan nan how college is different from high...     0.0000   \n",
       "7   nan nan nan nan Talking to the flashguides abo...     0.8271   \n",
       "8   Make sure that they set a good amount of time ...     0.8311   \n",
       "9   nan nan nan Buying books and when to do that. ...     0.0000   \n",
       "10  nan nan nan Timeline of billing process. Downt...     0.8074   \n",
       "11  nan nan nan nan nan To pass my classes and not...     0.4310   \n",
       "12  nan nan nan nan nan Be self sufficient (indepe...     0.3182   \n",
       "13  Level out the difficulty of the test to maybe ...     0.9982   \n",
       "14  nan nan nan nan Going into town and being able...     0.7506   \n",
       "\n",
       "    Sentiment_rolled  Polarity  \n",
       "0                  0   Neutral  \n",
       "1                  0   Neutral  \n",
       "2                  0   Neutral  \n",
       "3                  1  Positive  \n",
       "4                  1  Positive  \n",
       "5                  1  Positive  \n",
       "6                  0   Neutral  \n",
       "7                  1  Positive  \n",
       "8                  1  Positive  \n",
       "9                  0   Neutral  \n",
       "10                 1  Positive  \n",
       "11                 1  Positive  \n",
       "12                 1  Positive  \n",
       "13                 1  Positive  \n",
       "14                 1  Positive  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output2.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
